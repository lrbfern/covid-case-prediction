{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FinalData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Delete', 'Cough', 'Fever', 'Sore Throat', 'Shortness of Breath', 'Headache', 'Contact with Infectious', 'Test Result']\n",
    "del df['Delete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "columns = ['Cough', 'Fever', 'Sore Throat', 'Shortness of Breath', 'Headache', 'Contact with Infectious', 'Test Result']\n",
    "label_encoder = LabelEncoder()\n",
    "for column in columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])  # All the data is now numeric!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['Cough', 'Fever', 'Sore Throat', 'Shortness of Breath', 'Headache', 'Contact with Infectious']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['Test Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()\n",
    "data # Convert predictors to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.to_numpy()\n",
    "target # Convert target variable to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = target\n",
    "y.shape = (13762,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y) # X = predictors and y = target\n",
    "model = DecisionTreeClassifier(max_depth=20)# Create model\n",
    "model.fit(Xtrain, ytrain) # Train model to define ytrain outcomes as function of Xtrain attributes\n",
    "ypred = model.predict(Xtest) # Use newly trained model to predict outcomes based on new testing predictors\n",
    "print(\"{0} / {1} predicted correctly\".format(np.sum(ytest == ypred), len(ytest))) # How similar are the actual testing outcomes to the model's predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytest, ypred) # How close are the predictions of 'test result' in testing data to reality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "matrix = confusion_matrix(ytest, ypred, labels=model.classes_)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=model.classes_)\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, ypred, labels=model.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=0)\n",
    "model2 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model2.fit(Xtrain, ytrain)\n",
    "ypred = model2.predict(Xtest)\n",
    "print(\"{0} / {1} predicted correctly\".format(np.sum(ytest == ypred), len(ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "matrix = confusion_matrix(ytest, ypred, labels=model.classes_)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=model.classes_)\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, ypred, labels=model.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
